# M³-CHAT

**Memory-Native Neural Network for Language Modeling**

M³-CHAT (Manifold-Memory Multi-Modal Chat) is a GPT-competitive language model built on a memory-native architecture with manifold-based state representations.

> Generated by Claude Sonnet 4.5

## Features

- **Query-Key-Value Memory** - Transformer-like attention mechanism
- **Causal Time Gating** - Prevents future information leakage
- **Deep FFN Reasoning** - 4x expansion with GELU activation
- **RMSNorm + Gated Residuals** - Stable deep stacking
- **Multi-Step Internal Recurrence** - Internal thinking loop for self-refinement
- **Read-Write Memory Separation** - Prevents catastrophic forgetting
- **Global Scratchpad State** - Hidden chain-of-thought planning buffer

## Files

- `m3chat_v2.c` / `m3chat_v2.py` - Version 2 implementation
- `m3chat_v3.c` / `m3chat_v3.py` - Version 3 implementation (latest)

## Usage

```python
from m3chat_v3 import M3ChatV3

model = M3ChatV3(
    vocab_size=10000,
    embed_dim=128,
    hidden_size=256,
    memory_dim=64,
    manifold_dim=32,
    num_heads=4,
    max_seq_len=512,
    n_thoughts=3
)

# Train
tokens = [1, 2, 3, 4, 5]
loss = model.train_sequence(tokens)

# Generate
prompt = [1, 2, 3]
output = model.generate(prompt, max_new_tokens=20, temperature=0.8)
```

## Family

This project is part of the [MNNN (Memory-Native Neural Network)](https://github.com/hejhdiss/MEMORY-NATIVE-NEURAL_NETWORK) family.

## License

Licensed under GPL v3. See the `LICENSE` file in this repository for details.
